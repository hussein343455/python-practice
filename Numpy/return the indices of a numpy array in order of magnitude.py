# -*- coding: utf-8 -*-
"""code_submit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Acpj5sPoCyyKHnXZnPihe1QsuDEj5aIE

# instruction
* first create a virtual environment
* please follow https://pypi.org/project/pdftotext/ to install pdftotext
* install pandas, sklearn, numpy, matplotlib
"""

import pdftotext
from glob import glob

# Load your PDF
files=glob("New folder/*.pdf")

#read all pdf abstract and conclusion, if we read an abstract and failed to read conclusion, we put none at that place
data=[]
for i in files:
        
    try:
        conclusions=None
        with open (i, "rb") as f:
            pdf = pdftotext.PDF(f)
        for j in pdf:
            if 'abstract' in j.lower():
                abstract=j
            if 'conclusions' in j.lower().split()[1:10] or 'conclusion' in j.lower().split()[1:10]:
                conclusions=j

                
        data.append((abstract,conclusions))            
    except:
        pass

len(data)

#if a conclusion is none, we will remove that abstract also and concat abstract and conlusion
new_data=[i+j for i,j in data if j!=None ]

len(new_data)

#clean data
import re
clean_data=[]
for i in new_data:
    x=re.sub('[^\w\s]','',i.lower())#lower and remove punctuations
    x=re.sub('[\d+]','',x)#remove digist
    x=re.sub('[\n]',' ',x)#remove \n
    x=re.sub('[\r]',' ',x)#remove \r
    x=re.sub(' +',' ',x)#remove extra spaces
    clean_data.append(x)

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1,4),max_features=5000)
features = vectorizer.fit_transform(clean_data)

#apply k mean clustering
from sklearn.cluster import KMeans
num=5
kmeans = KMeans(n_clusters=num).fit_predict(features)

import pandas as pd
import numpy as np
def display_clusters(vectorz, kmean, vectorizer, n_words):
    df = pd.DataFrame(vectorz.todense()).groupby(kmean).mean()
    
    for i,j in df.iterrows():
        print('\nCluster {}'.format(i))
        print(','.join([vectorizer[t] for t in np.argsort(j)[-n_words:]]))

#result
display_clusters(features, kmeans, vectorizer.get_feature_names(), 30)

